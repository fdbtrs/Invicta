{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "5eTtD_OQvLUy"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "# Caculate the number of trainable parameters\n",
    "def _calc_width(net):\n",
    "    import numpy as np\n",
    "    net_params = filter(lambda p: p.requires_grad, net.parameters())\n",
    "    weight_count = 0\n",
    "    for param in net_params:\n",
    "        weight_count += np.prod(param.size())\n",
    "    return weight_count\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Agd5cqiyeU3o",
    "outputId": "29efe6b1-bf48-4328-a6c4-39064232e99d"
   },
   "outputs": [],
   "source": [
    "# Load Generator\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.label_emb = nn.Embedding(10, 10)\n",
    "        \n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(110, 256),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(256, 512),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(512, 1024),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(1024, 784),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "    \n",
    "    def forward(self, z, labels):\n",
    "        z = z.view(z.size(0), 100)\n",
    "        c = self.label_emb(labels)\n",
    "        x = torch.cat([z, c], 1)\n",
    "        out = self.model(x)\n",
    "        return out.view(x.size(0),1, 28, 28)\n",
    "generator=Generator().cuda()\n",
    "PATH=\"./generator_state.pt\"\n",
    "generator.load_state_dict(torch.load(PATH))\n",
    "generator.eval()\n",
    "def generate_digits( batch_size,noise_dim=100):\n",
    "    z = torch.randn(batch_size, noise_dim, device='cuda')\n",
    "    labels = torch.randint(0, 10, (batch_size,), device='cuda')\n",
    "    with torch.no_grad():\n",
    "        images = generator(z, labels)\n",
    "    return images,labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Agd5cqiyeU3o",
    "outputId": "29efe6b1-bf48-4328-a6c4-39064232e99d"
   },
   "outputs": [],
   "source": [
    "# Load MNIST dataset\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "train_dataset = torchvision.datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n",
    "test_dataset = torchvision.datasets.MNIST(root='./data', train=False, transform=transform, download=True)\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1000, shuffle=False)\n",
    "\n",
    "# Define the Teacher Model\n",
    "class TeacherModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TeacherModel, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.fc1 = nn.Linear(64*7*7, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2(x), 2))\n",
    "        x = x.view(-1, 64*7*7)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Define the Student Model\n",
    "class StudentModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(StudentModel, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 16, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, padding=1)\n",
    "        self.fc1 = nn.Linear(32*7*7, 64)\n",
    "        self.fc2 = nn.Linear(64, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2(x), 2))\n",
    "        x = x.view(-1, 32*7*7)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6070IhWmxOi_",
    "outputId": "be0a2550-8c77-4277-c57e-cd87b5372997"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.013882556930184364\n",
      "Epoch 2, Loss: 0.01285826787352562\n",
      "Epoch 3, Loss: 0.0016865209909155965\n",
      "Epoch 4, Loss: 0.026519469916820526\n",
      "Epoch 5, Loss: 0.007001764141023159\n",
      "Epoch 6, Loss: 0.030459141358733177\n",
      "Epoch 7, Loss: 0.0029465716797858477\n",
      "Epoch 8, Loss: 0.00031537990435026586\n",
      "Epoch 9, Loss: 0.0002815399202518165\n",
      "Epoch 10, Loss: 0.06564853340387344\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Train the Teacher Model\n",
    "teacher_model = TeacherModel().cuda()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(teacher_model.parameters(), lr=0.001)\n",
    "\n",
    "def train_standalone(model):\n",
    "    model.train()\n",
    "    for epoch in range(10):\n",
    "        for _ in range(len(train_loader)):\n",
    "            images, labels = generate_digits(64,100)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        print(f'Epoch {epoch+1}, Loss: {loss.item()}')\n",
    "\n",
    "train_standalone(teacher_model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TFS_n9jjgdmS",
    "outputId": "5393f92e-ae2e-4165-824d-47ed1d7ffba3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Teacher Model Accuracy: 94.39%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Evaluate both models\n",
    "def evaluate(model):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.cuda(), labels.cuda()\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    return 100 * correct / total\n",
    "\n",
    "teacher_acc = evaluate(teacher_model)\n",
    "print(f'Teacher Model Accuracy: {teacher_acc}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "pQUj_Kf-gyzT"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.043353449553251266\n",
      "Epoch 2, Loss: 0.003263709368184209\n",
      "Epoch 3, Loss: 0.011174341663718224\n",
      "Epoch 4, Loss: 0.007313861511647701\n",
      "Epoch 5, Loss: 0.00018130919488612562\n",
      "Epoch 6, Loss: 0.02880851924419403\n",
      "Epoch 7, Loss: 0.010320514440536499\n",
      "Epoch 8, Loss: 0.08353959023952484\n",
      "Epoch 9, Loss: 0.015486414544284344\n",
      "Epoch 10, Loss: 0.0006192185683175921\n",
      "Standalone Student Model Accuracy: 93.53%\n",
      "Epoch 1, Loss: 0.31982678174972534\n",
      "Epoch 2, Loss: 0.07603195309638977\n",
      "Epoch 3, Loss: 0.13417203724384308\n",
      "Epoch 4, Loss: 0.07136975973844528\n",
      "Epoch 5, Loss: 0.031091423705220222\n",
      "Epoch 6, Loss: 0.04806558042764664\n",
      "Epoch 7, Loss: 0.020203091204166412\n",
      "Epoch 8, Loss: 0.04069128632545471\n",
      "Epoch 9, Loss: 0.0252186618745327\n",
      "Epoch 10, Loss: 0.030238721519708633\n",
      "Student Model Accuracy: 94.53%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "standalone_student_model = StudentModel().cuda()\n",
    "optimizer = optim.Adam(standalone_student_model.parameters(), lr=0.001)\n",
    "\n",
    "train_standalone(standalone_student_model)\n",
    "standalone_student_acc = evaluate(standalone_student_model)\n",
    "print(f'Standalone Student Model Accuracy: {standalone_student_acc}%')\n",
    "\n",
    "# Knowledge Distillation Loss Function\n",
    "def kd_loss(student_logits, teacher_logits, labels, T=3, alpha=0.5):\n",
    "    kd_loss = nn.KLDivLoss(reduction='batchmean')(F.log_softmax(student_logits/T, dim=1),\n",
    "                                                  F.softmax(teacher_logits/T, dim=1)) * (T*T)\n",
    "    ce_loss = criterion(student_logits, labels)\n",
    "    return alpha * kd_loss + (1 - alpha) * ce_loss\n",
    "\n",
    "# Train the Student Model using Knowledge Distillation\n",
    "student_model = StudentModel().cuda()\n",
    "optimizer = optim.Adam(student_model.parameters(), lr=0.001)\n",
    "\n",
    "def train_student():\n",
    "    teacher_model.eval()\n",
    "    student_model.train()\n",
    "    for epoch in range(10):\n",
    "        for _ in range(len(train_loader)):\n",
    "            images, labels = generate_digits(64,100)\n",
    "            optimizer.zero_grad()\n",
    "            student_outputs = student_model(images)\n",
    "            with torch.no_grad():\n",
    "                teacher_outputs = teacher_model(images)\n",
    "            loss = kd_loss(student_outputs, teacher_outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        print(f'Epoch {epoch+1}, Loss: {loss.item()}')\n",
    "\n",
    "train_student()\n",
    "student_acc = evaluate(student_model)\n",
    "print(f'Student Model Accuracy: {student_acc}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RsLpbtAQwvea"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
