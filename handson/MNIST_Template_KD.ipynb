{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EXh2MPSbPCOU",
    "outputId": "6e4c54bc-acf6-4ce8-ad3c-c6b3563a0f63"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Load MNIST dataset\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "train_dataset = torchvision.datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n",
    "test_dataset = torchvision.datasets.MNIST(root='./data', train=False, transform=transform, download=True)\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1000, shuffle=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.014457643032073975\n",
      "Epoch 2, Loss: 0.03647108003497124\n",
      "Epoch 3, Loss: 0.006384856067597866\n",
      "Epoch 4, Loss: 0.006136614829301834\n",
      "Epoch 5, Loss: 0.006689592730253935\n",
      "Epoch 6, Loss: 6.137792661320418e-05\n",
      "Epoch 7, Loss: 0.030274182558059692\n",
      "Epoch 8, Loss: 0.0001408525713486597\n",
      "Epoch 9, Loss: 0.00022880287724547088\n",
      "Epoch 10, Loss: 0.0014746770029887557\n"
     ]
    }
   ],
   "source": [
    "# Define the Teacher Model\n",
    "class TeacherModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TeacherModel, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.fc1 = nn.Linear(64*7*7, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2(x), 2))\n",
    "        x = x.view(-1, 64*7*7)\n",
    "        feat = F.relu(self.fc1(x))\n",
    "        x = self.fc2(feat)\n",
    "        return x, feat\n",
    "\n",
    "# Define the Student Model\n",
    "class StudentModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(StudentModel, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 16, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, padding=1)\n",
    "        self.fc1 = nn.Linear(32*7*7, 64)\n",
    "        self.fc2 = nn.Linear(64, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2(x), 2))\n",
    "        x = x.view(-1, 32*7*7)\n",
    "        feat = F.relu(self.fc1(x))\n",
    "        x = self.fc2(feat)\n",
    "        return x, feat\n",
    "\n",
    "# Train the Teacher Model\n",
    "teacher_model = TeacherModel().cuda()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(teacher_model.parameters(), lr=0.001)\n",
    "\n",
    "def train_teacher():\n",
    "    teacher_model.train()\n",
    "    for epoch in range(10):\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.cuda(), labels.cuda()\n",
    "            optimizer.zero_grad()\n",
    "            outputs, _ = teacher_model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        print(f'Epoch {epoch+1}, Loss: {loss.item()}')\n",
    "\n",
    "train_teacher()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 1.2894935607910156\n",
      "Epoch 2, Loss: 1.0888124704360962\n",
      "Epoch 3, Loss: 0.8859511017799377\n",
      "Epoch 4, Loss: 1.0243275165557861\n",
      "Epoch 5, Loss: 0.67049640417099\n",
      "Epoch 6, Loss: 0.9033182263374329\n",
      "Epoch 7, Loss: 0.9728026986122131\n",
      "Epoch 8, Loss: 0.7961475253105164\n",
      "Epoch 9, Loss: 0.7647548913955688\n",
      "Epoch 10, Loss: 0.7021578550338745\n",
      "Teacher Model Accuracy: 99.01%\n",
      "Student Model Accuracy: 99.22%\n"
     ]
    }
   ],
   "source": [
    "# Feature-based Distillation Loss Function\n",
    "def feature_distillation_loss(student_feat, teacher_feat, student_logits, labels, alpha=0.7):\n",
    "    feat_loss = F.mse_loss(student_feat, F.avg_pool1d\n",
    "(teacher_feat.detach(),2))\n",
    "    ce_loss = criterion(student_logits, labels)\n",
    "    return alpha * feat_loss + (1 - alpha) * ce_loss\n",
    "\n",
    "# Train the Student Model using Feature-Based Distillation\n",
    "student_model = StudentModel().cuda()\n",
    "optimizer = optim.Adam(student_model.parameters(), lr=0.001)\n",
    "\n",
    "def train_student():\n",
    "    teacher_model.eval()\n",
    "    student_model.train()\n",
    "    for epoch in range(10):\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.cuda(), labels.cuda()\n",
    "            optimizer.zero_grad()\n",
    "            student_outputs, student_feat = student_model(images)\n",
    "            with torch.no_grad():\n",
    "                _, teacher_feat = teacher_model(images)\n",
    "            loss = feature_distillation_loss(student_feat, teacher_feat, student_outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        print(f'Epoch {epoch+1}, Loss: {loss.item()}')\n",
    "\n",
    "train_student()\n",
    "\n",
    "# Evaluate both models\n",
    "def evaluate(model):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.cuda(), labels.cuda()\n",
    "            outputs, _ = model(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    return 100 * correct / total\n",
    "\n",
    "teacher_acc = evaluate(teacher_model)\n",
    "student_acc = evaluate(student_model)\n",
    "print(f'Teacher Model Accuracy: {teacher_acc}%')\n",
    "print(f'Student Model Accuracy: {student_acc}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
